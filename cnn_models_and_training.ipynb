{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsimZz/Electo-Store/blob/master/cnn_models_and_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYxKxN7d8-TM"
      },
      "source": [
        "# Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.6.0 torchvision==0.7.0"
      ],
      "metadata": {
        "id": "2L2yIQF8ClBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFXkd5k3AHwk"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import image as mp_image\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1TzoXkISUiK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3WP-mEK9HtA"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR68ltZaBvxN"
      },
      "outputs": [],
      "source": [
        "data_origin = '/content/gdrive/MyDrive/Graduation Project/ds'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrrhwMnW_duQ"
      },
      "outputs": [],
      "source": [
        "!ls '/content/gdrive/MyDrive/Graduation Project/ds' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfXxBB_NClIv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "import tifffile as tiff\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjJohRYomIt_"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwSun8RGtSan"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqsdTHse-E-r"
      },
      "outputs": [],
      "source": [
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbBNBHoLJFkJ"
      },
      "source": [
        "## Akram's Suggested Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOTIcBQvJOiE"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class EuroSatDataset(Dataset):\n",
        "\n",
        "  def __init__(self,images,labels):\n",
        "    self.images = images\n",
        "    self.labels = labels\n",
        "  \n",
        "  def __getitem__(self,index):\n",
        "    return (self.images[index],self.labels[index])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nSsjUWHJTKi"
      },
      "outputs": [],
      "source": [
        "def tiff_loader(filename):\n",
        "  img = tiff.imread(filename)\n",
        "  img = torch.tensor(img.astype(np.float32), device=get_default_device())\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBKBt8jRCzmF"
      },
      "outputs": [],
      "source": [
        "data_transforms = transforms.Compose([transforms.ToTensor()])\n",
        "image_datasets = ImageFolder(root= data_origin,loader=tiff_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AICgrVM-KGLy"
      },
      "outputs": [],
      "source": [
        "## run this cell only once if you didn't save the EuroDataset class object\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "image_datasets = EuroSatDataset(images,labels)\n",
        "\n",
        "for image,label in tqdm(image_datasets):\n",
        "  images.append(image)\n",
        "  labels.append(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxcR6kqaVI5A"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "save_path = '/content/gdrive/MyDrive/Graduation Project/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXOfjg35NT9G"
      },
      "outputs": [],
      "source": [
        "## then we save the model in drive\n",
        "\n",
        "with open(save_path + 'image_datasets.pkl', 'wb') as handle:\n",
        "    pickle.dump(image_datasets, handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSIe8FHCNf24"
      },
      "outputs": [],
      "source": [
        "with open(save_path + 'images_dataset.pkl', 'rb') as handle:\n",
        "    image_datasets = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgmcbASbItVB"
      },
      "source": [
        "## Split The Dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDfa3o5qWuEA"
      },
      "outputs": [],
      "source": [
        "len(image_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxR-q9DIDkPX"
      },
      "outputs": [],
      "source": [
        "# split the dataset to train, test and validations sets\n",
        "# use random_split from pytorch.dataset module\n",
        "from torch.utils.data.dataset import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRKqg-W-kDwr"
      },
      "outputs": [],
      "source": [
        "# first take out the 20% of the dataset for validation\n",
        "lengths = [math.floor(len(image_datasets)*0.8),math.ceil(len(image_datasets)*0.2)]\n",
        "train_data, val_data = random_split(image_datasets,[21000,6000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WF8iI0CPmzZX"
      },
      "outputs": [],
      "source": [
        "# first take out the 20% of the train dataset for validation\n",
        "lengths = [math.floor(len(train_data)*0.8),math.ceil(len(train_data)*0.2)]\n",
        "train_data, test_data = random_split(train_data,[15000,6000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNJUN1_DnSfG"
      },
      "outputs": [],
      "source": [
        "print('Train Length = ' + str(len(train_data)))\n",
        "print('Validation Length = ' + str(len(val_data)))\n",
        "print('Test Length = ' + str(len(test_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvWXD59tDyRC"
      },
      "outputs": [],
      "source": [
        "device = get_default_device()\n",
        "batch_size = 64\n",
        "kw = {'num_workers': 8, 'pin_memory': True} if device == 'cuda' else {}\n",
        "\n",
        "train_loaders = DataLoader(train_data, batch_size = batch_size, shuffle = True, **kw)\n",
        "val_loaders = DataLoader(val_data, batch_size = batch_size, shuffle = True, **kw)\n",
        "test_loaders = DataLoader(test_data, batch_size = batch_size, shuffle = True, **kw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aglmBwlJA1Q7"
      },
      "source": [
        "# Model Archetictures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzPk6GFoB_Su"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class ImageClassifier(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['lrs'][-1], result['train_loss'],result['val_loss'], result['val_acc']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w-BQWzD812M"
      },
      "source": [
        "## ResNet-152 Model\n",
        "\n",
        "Residual network use the concept of residual blocks. it was proved that ResNet can perform very well in image classification tasks.\n",
        "The architecture of the network is explained in the figure below:\n",
        "\n",
        "![alt text](https://www.researchgate.net/profile/Dongyun-Lin/publication/324961229/figure/fig2/AS:633700479954944@1528097376059/The-basic-architecture-of-Resnet152.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWtwmiWtAwya"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, indentity_downsample=None, stride=1):\n",
        "        super(Block, self).__init__()\n",
        "        self.expansion = 4\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels,\n",
        "                               kernel_size=1, stride=1, padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels,\n",
        "                               kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion,\n",
        "                               kernel_size=1, stride=1, padding=0)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.indentity_downsample = indentity_downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        if(self.indentity_downsample is not None):\n",
        "            identity = self.indentity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\"\"\"\n",
        "  here we represent the Resnet which start with non-residual layers as follows:\n",
        "  a Conv with kernel size of 7 x 7 ---> Batch normlization ---> ReLU Function \n",
        "  ---> Maxpooling \n",
        "  after that we present the residual layers with 4 blocks each block repeated \n",
        "  (3, 8, 36, 3) respectively. the block architecture implemented in the Block class above.\n",
        "\"\"\"\n",
        "\n",
        "class ResNet(ImageClassifier):\n",
        "    def __init__(self, block, layers, image_channels, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # ResNet layers\n",
        "\n",
        "        self.layer1 = self._make_layer(\n",
        "            block, layers[0], out_channels=64, stride=1)\n",
        "        self.layer2 = self._make_layer(\n",
        "            block, layers[1], out_channels=128, stride=2)\n",
        "        self.layer3 = self._make_layer(\n",
        "            block, layers[2], out_channels=256, stride=2)\n",
        "        self.layer4 = self._make_layer(\n",
        "            block, layers[3], out_channels=512, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512*4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, num_residual_blocks, out_channels, stride):\n",
        "        indentity_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        # check for the identitiy layer so we know when to add a skip connection\n",
        "        if stride != 1 or self.in_channels != out_channels*4:\n",
        "            indentity_downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels*4, kernel_size=1, stride=stride), nn.BatchNorm2d(out_channels*4))\n",
        "        layers.append(\n",
        "            block(self.in_channels, out_channels, indentity_downsample, stride))\n",
        "        self.in_channels = out_channels*4\n",
        "\n",
        "        for _ in range(num_residual_blocks-1):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "\n",
        "def ResNet152(image_channels, num_classes):\n",
        "    return ResNet(Block, [3, 8, 36, 3], image_channels=image_channels, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c00x4gazshKH"
      },
      "outputs": [],
      "source": [
        "resnet_model = ResNet152(13,10)\n",
        "resnet_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L-N8iiUBJf3"
      },
      "source": [
        "## GoogleNet (InceptionNet) Model\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Bo-Zhao-67/publication/312515254/figure/fig3/AS:489373281067012@1493687090916/nception-module-of-GoogLeNet-This-figure-is-from-the-original-paper-10.png\" width=500>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DorEuM-ZBroB"
      },
      "outputs": [],
      "source": [
        "class GoogleNet(ImageClassifier):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(GoogleNet, self).__init__()\n",
        "\n",
        "        self.conv1 = ConvBlock(\n",
        "            in_channels=in_channels, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
        "\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.conv2 = ConvBlock(\n",
        "            in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.inception3a = InceptionBlock(\n",
        "            in_channels=192, out_1x1=64, red_3x3=96, out_3x3=128, red_5x5=16, out_5x5=32, out_1x1pool=32)\n",
        "        self.inception3b = InceptionBlock(\n",
        "            in_channels=256, out_1x1=128, red_3x3=128, out_3x3=192, red_5x5=32, out_5x5=96, out_1x1pool=64)\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.inception4a = InceptionBlock(\n",
        "            in_channels=480, out_1x1=192, red_3x3=96, out_3x3=208, red_5x5=16, out_5x5=48, out_1x1pool=64)\n",
        "        self.inception4b = InceptionBlock(\n",
        "            in_channels=512, out_1x1=160, red_3x3=112, out_3x3=224, red_5x5=24, out_5x5=64, out_1x1pool=64)\n",
        "        self.inception4c = InceptionBlock(\n",
        "            in_channels=512, out_1x1=128, red_3x3=128, out_3x3=256, red_5x5=24, out_5x5=64, out_1x1pool=64)\n",
        "        self.inception4d = InceptionBlock(\n",
        "            in_channels=512, out_1x1=112, red_3x3=144, out_3x3=288, red_5x5=32, out_5x5=64, out_1x1pool=64)\n",
        "        self.inception4e = InceptionBlock(\n",
        "            in_channels=528, out_1x1=256, red_3x3=160, out_3x3=320, red_5x5=32, out_5x5=128, out_1x1pool=128)\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.inception5a = InceptionBlock(\n",
        "            in_channels=832, out_1x1=256, red_3x3=160, out_3x3=320, red_5x5=32, out_5x5=128, out_1x1pool=128)\n",
        "        self.inception5b = InceptionBlock(\n",
        "            in_channels=832, out_1x1=384, red_3x3=192, out_3x3=384, red_5x5=48, out_5x5=128, out_1x1pool=128)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(p=0.4)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = self.conv1(input)\n",
        "        input = self.maxpool1(input)\n",
        "        input = self.conv2(input)\n",
        "        input = self.maxpool2(input)\n",
        "\n",
        "        input = self.inception3a(input)\n",
        "        input = self.inception3b(input)\n",
        "        input = self.maxpool3(input)\n",
        "\n",
        "        input = self.inception4a(input)\n",
        "        input = self.inception4b(input)\n",
        "        input = self.inception4c(input)\n",
        "        input = self.inception4d(input)\n",
        "        input = self.inception4e(input)\n",
        "        input = self.maxpool4(input)\n",
        "\n",
        "        input = self.inception5a(input)\n",
        "        input = self.inception5b(input)\n",
        "\n",
        "        input = self.avgpool(input)\n",
        "        input = input.reshape(input.shape[0], -1)\n",
        "        input = self.dropout(input)\n",
        "        input = self.fc(input)\n",
        "        return input\n",
        "\n",
        "\n",
        "class InceptionBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool):\n",
        "        super(InceptionBlock, self).__init__()\n",
        "\n",
        "        self.branch1 = ConvBlock(\n",
        "            in_channels=in_channels, out_channels=out_1x1, kernel_size=1)\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            ConvBlock(in_channels=in_channels,\n",
        "                      out_channels=red_3x3, kernel_size=1),\n",
        "            ConvBlock(red_3x3, out_3x3, kernel_size=3, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            ConvBlock(in_channels=in_channels,\n",
        "                      out_channels=red_5x5, kernel_size=1),\n",
        "            ConvBlock(red_5x5, out_5x5, kernel_size=5, padding=2)\n",
        "        )\n",
        "\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            ConvBlock(in_channels=in_channels,\n",
        "                      out_channels=out_1x1pool, kernel_size=1)\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        # N x filterss x 64 x 64\n",
        "        return torch.cat([\n",
        "            self.branch1(input),\n",
        "            self.branch2(input),\n",
        "            self.branch3(input),\n",
        "            self.branch4(input),\n",
        "        ], 1)\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
        "                              out_channels=out_channels, **kwargs)\n",
        "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.relu(self.batch_norm(self.conv(input)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLb2rp7yCRCv"
      },
      "outputs": [],
      "source": [
        "googleNet_model = GoogleNet(13,10)\n",
        "googleNet_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EfficientNet Model \n"
      ],
      "metadata": {
        "id": "L4phyY29NgX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from math import ceil\n",
        "\n",
        "base_model = [\n",
        "    # expand_ratio, channels, repeats, stride, kernel_size\n",
        "    [1, 16, 1, 1, 3],\n",
        "    [6, 24, 2, 2, 3],\n",
        "    [6, 40, 2, 2, 5],\n",
        "    [6, 80, 3, 2, 3],\n",
        "    [6, 112, 3, 1, 5],\n",
        "    [6, 192, 4, 2, 5],\n",
        "    [6, 320, 1, 1, 3],\n",
        "]\n",
        "\n",
        "phi_values = {\n",
        "    # tuple of: (phi_value, resolution, drop_rate)\n",
        "    \"b0\": (0, 224, 0.2),  # alpha, beta, gamma, depth = alpha ** phi\n",
        "    \"b1\": (0.5, 240, 0.2),\n",
        "    \"b2\": (1, 260, 0.3),\n",
        "    \"b3\": (2, 300, 0.3),\n",
        "    \"b4\": (3, 380, 0.4),\n",
        "    \"b5\": (4, 456, 0.4),\n",
        "    \"b6\": (5, 528, 0.5),\n",
        "    \"b7\": (6, 600, 0.5),\n",
        "}\n",
        "\n",
        "class CNNBlock(nn.Module):\n",
        "    def __init__(\n",
        "            self, in_channels, out_channels, kernel_size, stride, padding, groups=1\n",
        "    ):\n",
        "        super(CNNBlock, self).__init__()\n",
        "        self.cnn = nn.Conv2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size,\n",
        "            stride,\n",
        "            padding,\n",
        "            groups=groups,\n",
        "            bias=False,\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.silu = nn.SiLU() # SiLU <-> Swish\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.silu(self.bn(self.cnn(x)))\n",
        "\n",
        "class SqueezeExcitation(nn.Module):\n",
        "    def __init__(self, in_channels, reduced_dim):\n",
        "        super(SqueezeExcitation, self).__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1), # C x H x W -> C x 1 x 1\n",
        "            nn.Conv2d(in_channels, reduced_dim, 1),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(reduced_dim, in_channels, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.se(x)\n",
        "\n",
        "class InvertedResidualBlock(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size,\n",
        "            stride,\n",
        "            padding,\n",
        "            expand_ratio,\n",
        "            reduction=4, # squeeze excitation\n",
        "            survival_prob=0.8, # for stochastic depth\n",
        "    ):\n",
        "        super(InvertedResidualBlock, self).__init__()\n",
        "        self.survival_prob = 0.8\n",
        "        self.use_residual = in_channels == out_channels and stride == 1\n",
        "        hidden_dim = in_channels * expand_ratio\n",
        "        self.expand = in_channels != hidden_dim\n",
        "        reduced_dim = int(in_channels / reduction)\n",
        "\n",
        "        if self.expand:\n",
        "            self.expand_conv = CNNBlock(\n",
        "                in_channels, hidden_dim, kernel_size=3, stride=1, padding=1,\n",
        "            )\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            CNNBlock(\n",
        "                hidden_dim, hidden_dim, kernel_size, stride, padding, groups=hidden_dim,\n",
        "            ),\n",
        "            SqueezeExcitation(hidden_dim, reduced_dim),\n",
        "            nn.Conv2d(hidden_dim, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "        )\n",
        "\n",
        "    def stochastic_depth(self, x):\n",
        "        if not self.training:\n",
        "            return x\n",
        "\n",
        "        binary_tensor = torch.rand(x.shape[0], 1, 1, 1, device=x.device) < self.survival_prob\n",
        "        return torch.div(x, self.survival_prob) * binary_tensor\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.expand_conv(inputs) if self.expand else inputs\n",
        "\n",
        "        if self.use_residual:\n",
        "            return self.stochastic_depth(self.conv(x)) + inputs\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class EfficientNet(ImageClassifier):\n",
        "    def __init__(self, version, num_classes):\n",
        "        super(EfficientNet, self).__init__()\n",
        "        width_factor, depth_factor, dropout_rate = self.calculate_factors(version)\n",
        "        last_channels = ceil(1280 * width_factor)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.features = self.create_features(width_factor, depth_factor, last_channels)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(last_channels, num_classes),\n",
        "        )\n",
        "\n",
        "    def calculate_factors(self, version, alpha=1.2, beta=1.1):\n",
        "        phi, res, drop_rate = phi_values[version]\n",
        "        depth_factor = alpha ** phi\n",
        "        width_factor = beta ** phi\n",
        "        return width_factor, depth_factor, drop_rate\n",
        "\n",
        "    def create_features(self, width_factor, depth_factor, last_channels):\n",
        "        channels = int(32 * width_factor)\n",
        "        features = [CNNBlock(13, channels, 3, stride=2, padding=1)]\n",
        "        in_channels = channels\n",
        "\n",
        "        for expand_ratio, channels, repeats, stride, kernel_size in base_model:\n",
        "            out_channels = 4*ceil(int(channels*width_factor) / 4)\n",
        "            layers_repeats = ceil(repeats * depth_factor)\n",
        "\n",
        "            for layer in range(layers_repeats):\n",
        "                features.append(\n",
        "                    InvertedResidualBlock(\n",
        "                        in_channels,\n",
        "                        out_channels,\n",
        "                        expand_ratio=expand_ratio,\n",
        "                        stride = stride if layer == 0 else 1,\n",
        "                        kernel_size=kernel_size,\n",
        "                        padding=kernel_size//2, # if k=1:pad=0, k=3:pad=1, k=5:pad=2\n",
        "                    )\n",
        "                )\n",
        "                in_channels = out_channels\n",
        "\n",
        "        features.append(\n",
        "            CNNBlock(in_channels, last_channels, kernel_size=1, stride=1, padding=0)\n",
        "        )\n",
        "\n",
        "        return nn.Sequential(*features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.features(x))\n",
        "        return self.classifier(x.view(x.shape[0], -1))\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    version = \"b0\"\n",
        "    phi, res, drop_rate = phi_values[version]\n",
        "    num_examples, num_classes = len(val_data)+len(train_data)+len(test_data), 10\n",
        "    model = EfficientNet(\n",
        "        version=version,\n",
        "        num_classes=num_classes,\n",
        "    ).to(device)\n",
        "\n",
        "    return model # (num_examples, num_classes)\n",
        "\n",
        "enet_model=build_model()"
      ],
      "metadata": {
        "id": "vMBNTGFONdR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "738LnrnBTAWj"
      },
      "source": [
        "# Using GPU for Training\n",
        "To seamlessly use a **GPU**, if one is available, we define a couple of helper functions (`get_default_device` & `to_device`) and a helper class `DeviceDataLoader` to move our model & data to the **GPU as required**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlFLHVZfTB3Q"
      },
      "outputs": [],
      "source": [
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Fl3Nbe-UGmY"
      },
      "outputs": [],
      "source": [
        "\n",
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmPP2Lq5C5vi"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy Calculation"
      ],
      "metadata": {
        "id": "GPUVmyNfT0Du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "3_-nOQRsT4zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    total_acc = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.to(device=device)\n",
        "            targets = targets.to(device=device)\n",
        "            \n",
        "            scores = model(inputs)\n",
        "            _, predictions = scores.max(1)\n",
        "            total_acc += accuracy_score(targets.cpu(),predictions.cpu())\n",
        "            num_samples += 1\n",
        "        \n",
        "        return(f'Got {num_correct} / {num_samples} with accuracy {total_acc/float(num_samples)}') \n",
        "    \n",
        "    model.train()"
      ],
      "metadata": {
        "id": "fbijzM44UARq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZDe490ZR3C4"
      },
      "source": [
        "# Training The ResNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij0PfBleRhr0"
      },
      "outputs": [],
      "source": [
        "resnet_model = to_device(resnet_model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9JxlyRkWaM3"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loaders):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loaders]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "    \n",
        "    # Set up cutom optimizer with weight decay\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # Set up one-cycle learning rate scheduler\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
        "                                                steps_per_epoch=len(train_loader))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            if grad_clip: \n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Record & update learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "\n",
        "\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "\n",
        "    #save the model parameters\n",
        "    torch.save({\n",
        "            'epochs': epochs,\n",
        "            'resnet_model': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'weight_decay': weight_decay,\n",
        "            'scheduler': sched,\n",
        "            'learning_rates': lrs,\n",
        "            'grad_clip': grad_clip,\n",
        "            'train_losses': train_losses,\n",
        "        }, save_path+'saved_models/resnet_model/resnet_model.pth')\n",
        "    with open(save_path + 'saved_models/resnet_model/resnet_file.pkl', 'wb') as handle:\n",
        "      pickle.dump(history, handle)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En0XZdcl-3gZ"
      },
      "outputs": [],
      "source": [
        "train_loaders = DeviceDataLoader(train_loaders, device)\n",
        "val_loaders = DeviceDataLoader(val_loaders, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWfiQzQtWUlP"
      },
      "outputs": [],
      "source": [
        "history = [evaluate(resnet_model, val_loaders=val_loaders)]\n",
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhMFpZuTH2JR"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtS3A093H2uG"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history += fit_one_cycle(epochs, max_lr, resnet_model, train_loaders, val_loaders, \n",
        "                             grad_clip=grad_clip, \n",
        "                             weight_decay=weight_decay, \n",
        "                             opt_func=opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwoBm_Qzj4uA"
      },
      "outputs": [],
      "source": [
        "saved_model = torch.load(save_path+'saved_models/resnet_model/resnet_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB0uDECNj_XY"
      },
      "outputs": [],
      "source": [
        "saved_resnet_model = ResNet152(13,10)\n",
        "saved_resnet_model = to_device(saved_resnet_model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_XL9OaukCpv"
      },
      "outputs": [],
      "source": [
        "saved_resnet_model.load_state_dict(saved_model['resnet_model'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ls41KpKlnnW"
      },
      "outputs": [],
      "source": [
        "check_accuracy(train_loaders,resnet_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfn0f8lpmSTJ"
      },
      "source": [
        "# Training The GoogleNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7UTUlPkmSTl"
      },
      "outputs": [],
      "source": [
        "googleNet_model = to_device(googleNet_model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq3M1bpemSTm"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loaders):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loaders]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "    \n",
        "    # Set up cutom optimizer with weight decay\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # Set up one-cycle learning rate scheduler\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
        "                                                steps_per_epoch=len(train_loader))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            if grad_clip: \n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Record & update learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "\n",
        "\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "\n",
        "    #save the model parameters\n",
        "    torch.save({\n",
        "            'epochs': epochs,\n",
        "            'googleNet_model': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'weight_decay': weight_decay,\n",
        "            'scheduler': sched,\n",
        "            'learning_rates': lrs,\n",
        "            'grad_clip': grad_clip,\n",
        "            'train_losses': train_losses,\n",
        "        }, save_path+'saved_models/googleNet_model/googleNet_model.pth')\n",
        "    with open(save_path + 'saved_models/googleNet_model/googleNet_file.pkl', 'wb') as handle:\n",
        "      pickle.dump(history, handle)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_u_d9TMmSTn"
      },
      "outputs": [],
      "source": [
        "train_loaders = DeviceDataLoader(train_loaders, device)\n",
        "val_loaders = DeviceDataLoader(val_loaders, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_I5jH2xmSTn"
      },
      "outputs": [],
      "source": [
        "history = [evaluate(googleNet_model, val_loaders=val_loaders)]\n",
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4agn6z93mSTo"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ybjn57bhmSTp"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history += fit_one_cycle(epochs, max_lr, googleNet_model, train_loaders, val_loaders, \n",
        "                             grad_clip=grad_clip, \n",
        "                             weight_decay=weight_decay, \n",
        "                             opt_func=opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylNw0hsAmSTq"
      },
      "outputs": [],
      "source": [
        "saved_model = torch.load(save_path+'saved_models/googleNet_model/googleNet_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiWQVVOImSTq"
      },
      "outputs": [],
      "source": [
        "saved_googleNet_model = GoogleNet(13,10)\n",
        "saved_googleNet_model = to_device(saved_googleNet_model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygsH-EyKmSTr"
      },
      "outputs": [],
      "source": [
        "saved_googleNet_model.load_state_dict(saved_model['googleNet_model'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-KjA012mSTr"
      },
      "outputs": [],
      "source": [
        "check_accuracy(train_loaders,googleNet_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h8U1sbxO3sU"
      },
      "source": [
        "# Training The EffNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S0uE6YfO3sW"
      },
      "outputs": [],
      "source": [
        "enet_model = to_device(enet_model, device)\n",
        "enet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUJDHq8rO3sX"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loaders):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loaders]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "    \n",
        "    # Set up cutom optimizer with weight decay\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # Set up one-cycle learning rate scheduler\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
        "                                                steps_per_epoch=len(train_loader))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        t0 = time.perf_counter()\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            if grad_clip: \n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Record & update learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "\n",
        "\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "\n",
        "    #save the model parameters\n",
        "    torch.save({\n",
        "            'epochs': epochs,\n",
        "            'googleNet_model': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'weight_decay': weight_decay,\n",
        "            'scheduler': sched,\n",
        "            'learning_rates': lrs,\n",
        "            'grad_clip': grad_clip,\n",
        "            'train_losses': train_losses,\n",
        "        }, save_path+'saved_models/effNet_model/effNet_model.pth')\n",
        "    with open(save_path + 'saved_models/effNet_model/effNet_file.pkl', 'wb') as handle:\n",
        "      pickle.dump(history, handle)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6Ya8YayO3sY"
      },
      "outputs": [],
      "source": [
        "train_loaders = DeviceDataLoader(train_loaders, device)\n",
        "val_loaders = DeviceDataLoader(val_loaders, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKBPYheMO3sY"
      },
      "outputs": [],
      "source": [
        "history = [evaluate(enet_model, val_loaders=val_loaders)]\n",
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNlAqpmPO3sZ"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7xBIVaHO3sa"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history += fit_one_cycle(epochs, max_lr, enet_model, train_loaders, val_loaders, \n",
        "                             grad_clip=grad_clip, \n",
        "                             weight_decay=weight_decay, \n",
        "                             opt_func=opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVkdKKZeWDvC"
      },
      "outputs": [],
      "source": [
        "saved_model = torch.load(save_path+'saved_models/effNet_model/effNet_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCFCUFSlSZV-"
      },
      "outputs": [],
      "source": [
        "saved_effNet_model = EfficientNet('b0',10)\n",
        "saved_effNet_model = to_device(saved_effNet_model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyir59GAS1Uv"
      },
      "outputs": [],
      "source": [
        "saved_effNet_model.load_state_dict(saved_model['effNet_model'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w90q3BBFA6J"
      },
      "outputs": [],
      "source": [
        "check_accuracy(train_loaders,saved_effNet_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWjBMhXk8hNI"
      },
      "source": [
        "#Other Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBYfHYml6kvR"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_YgZF706uyG"
      },
      "outputs": [],
      "source": [
        "def check_metric(loader, model,metric,average,score):\n",
        "    total_metric = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.to(device=device)\n",
        "            targets = targets.to(device=device)\n",
        "            scores = model(inputs)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_samples += 1\n",
        "            total_metric  += metric(targets.cpu(),predictions.cpu(),average=average)\n",
        "        \n",
        "        return(f'Got {score} Score {total_metric/float(num_samples)}') \n",
        "    \n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWsgZdxT8N__"
      },
      "source": [
        "##Precision, Recall and F1 Score For GoogleNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDCCAH_28bRl"
      },
      "outputs": [],
      "source": [
        "check_metric(test_loaders,googleNet_model,metrics.recall_score,'macro','Recall')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_NkKIWl8rVu"
      },
      "outputs": [],
      "source": [
        "check_metric(test_loaders,googleNet_model,metrics.precision_score,'macro','Precision')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrnKDu7a7Flf"
      },
      "outputs": [],
      "source": [
        "check_metric(test_loaders,googleNet_model,metrics.f1_score,'macro','F1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr14eIW35QwW"
      },
      "source": [
        "# Precision, Recall and F1 score for ResNet152"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIuymxam5Xgc"
      },
      "outputs": [],
      "source": [
        "check_metric(test_loaders,saved_resnet_model,metrics.recall_score,'macro','Recall')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNuyIkiU5c0n"
      },
      "outputs": [],
      "source": [
        "check_metric(test_loaders,saved_resnet_model,metrics.precision_score,'macro','Precision')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quCzxBcX5l5y"
      },
      "outputs": [],
      "source": [
        "check_metric(test_loaders,saved_resnet_model,metrics.f1_score,'macro','F1')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "kYxKxN7d8-TM",
        "s3WP-mEK9HtA",
        "fbBNBHoLJFkJ",
        "fgmcbASbItVB",
        "zeTzfMcZ9sxr",
        "B8XaOODBTdPa",
        "0L-N8iiUBJf3",
        "738LnrnBTAWj",
        "Zfn0f8lpmSTJ",
        "sWjBMhXk8hNI",
        "EWsgZdxT8N__",
        "Jr14eIW35QwW",
        "5qUIlbvP8Ss5"
      ],
      "name": "cnn_models_and_training.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}